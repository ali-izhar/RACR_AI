# config/model_config.yaml

# All top-level keys must be singular, e.g., dataset, dataloader, model

# DEFAULT CONFIGURATIONS
# ---------------------
default:
  device: cuda                 # Computation device (cuda for GPU, cpu for CPU). Will default to cpu
  class: default               # Default class to use (current options: default, custom)
  mode: eval                   # Model operation mode ('train' for training, 'eval' for evaluation)
  depth: 2                     # Depth for recursive model exploration
  flush_buffer_size: 100       # Number of inferences before flushing results to storage
  warmup_iterations: 2         # Number of warmup iterations to stabilize model performance
  default_model: alexnet       # Default model to use (current options: alexnet, yolo, custom)
  default_dataset: imagenet    # Default dataset to use (current options: onion, imagenet)
  run_on_edge: false           # Flag to determine if running on Edge device (true) or locally (false)
  log_level: INFO              # Default log level (INFO, DEBUG, ERROR)
  log_file: app.log            # Default log file (null for no file logging)

# MODEL CONFIGURATIONS
# ---------------------
model:
  alexnet:
    model_name: alexnet        # Name of the model (must match torchvision model names)
    version: null              # Version of the model (if applicable)
    pretrained: true           # Whether to use pretrained weights
    weight_path: null          # Path to custom weights file
    input_size: [3, 224, 224]  # Input tensor size [channels, height, width]
    split_layer: 5             # Layer to split the model at
    hook_style: pre            # Hook insertion style ('pre' or 'post')
    save_layers: [2, 4, 6]     # Layer indices to save intermediate outputs
    log_file: alexnet.log      # Log file for the model

  yolo:
    model_name: yolov8s        # YOLO model variant (e.g., yolov8s, yolov8m, yolov8l)
    version: null              # Version of YOLO (if applicable)
    pretrained: false          # Whether to use pretrained weights
    weight_path: data/onion/weights/best.pt  # Path to custom weights file
    input_size: [3, 224, 224]  # Input tensor size [channels, height, width]
    split_layer: 5             # Layer to split the model at
    hook_style: post           # Hook insertion style ('pre' or 'post')
    save_layers: [2, 4, 6]     # Layer indices to save intermediate outputs
    log_file: yolo.log         # Log file for the model

  # custom:
  #   model_name: custom_model   # Name for your custom model
  #   version: null              # Version of your custom model (if applicable)
  #   input_size: [3, 256, 256]  # Input tensor size [channels, height, width]
  #   hook_style: pre            # Hook insertion style ('pre' or 'post')
  #   save_layers: [3, 5, 7]     # Layer indices to save intermediate outputs
  #   dropout_rate: 0.5        # Dropout rate for custom model (if applicable)
  #   custom_layer_sizes: [128, 64]  # Custom layer sizes (if applicable)

# DATASET CONFIGURATIONS
# ---------------------
dataset:
  onion:
    module: onion              # Python module name for the dataset (without .py extension)
    class: OnionDataset        # Class name of the dataset
    class_names: ["with_weeds", "without_weeds"]  # Class names for the dataset
    args:
      root: data/onion/testing # Root directory of the dataset
      transform: null          # Data transformations (null for default transformations)
      max_samples: -1          # Maximum number of samples to load (-1 for all samples)

  imagenet:
    module: imagenet           # Python module name for the dataset
    class: ImagenetDataset     # Class name of the dataset
    class_names: null          # Class names for the dataset
    args:
      root: data/imagenet      # Root directory of the dataset
      transform: null          # Data transformations (null for default)
      max_samples: -1          # Maximum number of samples to load (-1 for all samples)

  # cifar10:
  #   module: cifar10
  #   class: CIFAR10Dataset
  #   class_names: null          # Class names for the dataset
  #   args:
  #     root: data/cifar10        # Root directory for CIFAR10 dataset
  #     transform: default_transform  # Use default transformations
  #     download: true            # Whether to download the dataset if not present

# DATALOADER CONFIGURATIONS
# ---------------------
dataloader:
  batch_size: 1                # Number of samples per batch
  shuffle: false               # Whether to shuffle the data
  num_workers: 4               # Number of subprocesses for data loading (adjust based on CPU cores)
  collate_fn: null             # Custom collate function (set dynamically in run_dataset.py)
